Batch size = how many training examples the model processes before updating its weights.

Instead of learning from one example at a time, the model learns from a batch.





Supervised
----------
Supervised Learning is a type of Machine Learning where:

You train a model using labeled data

Each data point has:

Input (X) â†’ features

Output (Y) â†’ correct answer (label)


Classification
--------------
Logistic Regression

KNN

Naive Bayes

SVM

Decision Tree

Random Forest

Neural Networks

Regression
---------
Linear Regression

Polynomial Regression

Ridge / Lasso

SVR

Neural Networks


| Problem               | Loss Function             |
| --------------------- | ------------------------- |
| Regression            | MSE, MAE                  |
| Binary Classification | Binary Cross Entropy      |
| Multi-class           | Categorical Cross Entropy |

| Metric    | Meaning                       |
| --------- | ----------------------------- |
| Accuracy  | Overall correctness           |
| Precision | Correct positives             |
| Recall    | Found positives               |
| F1-score  | Balance of precision & recall |
| ROC-AUC   | Threshold independent         |



K-Nearest Neighbors (KNN)
------------------
KNN is a supervised, non-parametric, lazy learning algorithm used for classification and regression.
1ï¸âƒ£Choose the number K
2ï¸âƒ£ Calculate distance from new point to all training points
3ï¸âƒ£ Select K nearest neighbors
4ï¸âƒ£ Classification â†’ majority vote
5ï¸âƒ£ Regression â†’ average of values

Recommendation Systems (Movies / Products)

Scenario:
You watch action & sci-fi movies.
How KNN works:
Find users with similar viewing history
Recommend what they liked
ğŸ‘‰ â€œUsers similar to you liked this.â€

Naive Bayes
----------
Naive Bayes is a supervised, probabilistic classification algorithm based on Bayesâ€™ Theorem, with the 
â€œnaiveâ€ assumption that features are independent.
P(Câˆ£X)=P(Xâˆ£C)P(C)/P(X)

Decision Tree
-------------
A Decision Tree is a supervised learning algorithm that makes decisions by asking a series of questions and 
splitting data like a tree structure.
Loan Approval System ğŸ’³

Questions (nodes):

Is income > 50,000?

Credit score > 700?

Existing loans?

Decision (leaf):

Approve / Reject loan

ğŸ‘‰ Exactly how banks think.

Random Forest
------------
Random Forest is an ensemble learning algorithm that builds multiple decision trees and combines their 
results to make a more accurate and stable prediction.
Instead of trusting one tree, it trusts the wisdom of many trees.

example:Stock Market Trend Prediction

Support Vector Machine (SVM)
----------------------------
SVM is a supervised learning algorithm that finds the optimal hyperplane which separates 
data points of different classes with the maximum margin.
Face Recognition ğŸ‘¤

High-dimensional pixel data

SVM separates facial features effectively



Unsupervised
------------
Unsupervised Learning is a type of machine learning where the model is trained on unlabeled data and tries to discover hidden patterns, structures, or 
relationships in the data without knowing the correct output in advance.

1. K-Means Clustering
---------------------
K-Means is an unsupervised learning algorithm that groups data into K clusters based on similarity.
1ï¸âƒ£ Choose number of clusters K
2ï¸âƒ£ Randomly initialize K centroids
3ï¸âƒ£ Assign each data point to the nearest centroid
4ï¸âƒ£ Recalculate centroids (mean of cluster points)
5ï¸âƒ£ Repeat steps 3â€“4 until centroids stop changing

1ï¸âƒ£ Customer Segmentation ğŸ›’

Group customers by buying behavior

Used in marketing campaigns

2ï¸âƒ£ Image Compression ğŸ–¼ï¸

Group similar pixel colors

Reduce number of colors

3ï¸âƒ£ Document Clustering ğŸ“„

Group similar news articles

Topic discovery


Hierarchical Clustering
-----------------------
Hierarchical Clustering is an unsupervised learning algorithm that builds a hierarchy (tree) of 
clusters instead of forming a single flat partition.

Start with data points and keep merging or splitting clusters step by step, creating a hierarchy.


1ï¸âƒ£ Start with N clusters (each point = one cluster)
2ï¸âƒ£ Compute distance between all clusters
3ï¸âƒ£ Merge the two closest clusters
4ï¸âƒ£ Recalculate distances
5ï¸âƒ£ Repeat until one cluster remains

1ï¸âƒ£ Document Clustering ğŸ“„

Group research papers by topic

Subtopics naturally form

2ï¸âƒ£ Biological Classification ğŸ§¬

Species â†’ genus â†’ family â†’ kingdom

Natural hierarchy

3ï¸âƒ£ Customer Segmentation ğŸ›’

High-level groups â†’ sub-groups

Useful for marketing strategies


Principal Component Analysis (PCA)
--------------------------------
PCA is an unsupervised dimensionality reduction technique that transforms high-dimensional 
data into a lower-dimensional space while preserving maximum variance.

1ï¸âƒ£ Standardize the data
2ï¸âƒ£ Compute covariance matrix
3ï¸âƒ£ Calculate eigenvalues & eigenvectors
4ï¸âƒ£ Choose top K eigenvectors
5ï¸âƒ£ Project data onto new axes

1ï¸âƒ£ Image Compression ğŸ–¼ï¸

Reduce pixel dimensions

Keep important visual features

2ï¸âƒ£ Face Recognition ğŸ‘¤

Reduce facial feature space

Faster matching

3ï¸âƒ£ Data Visualization ğŸ“Š

Convert high-dimensional data into 2D/3D plots
































	â€‹

